{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74a0ef9",
   "metadata": {},
   "source": [
    "# Time Series Analysis: Alzheimer's disease (No cog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb98bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b436dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209100 entries, 0 to 209099\n",
      "Data columns (total 32 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   NACCID        209100 non-null  object \n",
      " 1   visit_num     209100 non-null  int64  \n",
      " 2   NACCAGE       209100 non-null  int64  \n",
      " 3   SEX           209100 non-null  int64  \n",
      " 4   EDUC          209100 non-null  int64  \n",
      " 5   HYPERTEN      209100 non-null  int64  \n",
      " 6   DIABETES      209100 non-null  int64  \n",
      " 7   HYPERCHO      209100 non-null  int64  \n",
      " 8   CVHATT        209100 non-null  int64  \n",
      " 9   STROKE        209100 non-null  int64  \n",
      " 10  TOBAC30       209100 non-null  int64  \n",
      " 11  ALCOHOL       209100 non-null  int64  \n",
      " 12  NACCBMI       209100 non-null  float64\n",
      " 13  NACCFAM       209100 non-null  int64  \n",
      " 14  NACCALZD      209100 non-null  int64  \n",
      " 15  VISITYR       209100 non-null  int64  \n",
      " 16  VISITMO       209100 non-null  int64  \n",
      " 17  VISITDAY      209100 non-null  int64  \n",
      " 18  BPSYS         209100 non-null  float64\n",
      " 19  COGMODE       209100 non-null  int64  \n",
      " 20  DEPD          209100 non-null  int64  \n",
      " 21  MEMORY        209100 non-null  float64\n",
      " 22  ORIENT        209100 non-null  float64\n",
      " 23  BPDIAS        209100 non-null  float64\n",
      " 24  HYPERTEN_BIN  209100 non-null  int64  \n",
      " 25  DIABETES_BIN  209100 non-null  int64  \n",
      " 26  HYPERCHO_BIN  209100 non-null  int64  \n",
      " 27  CVHATT_BIN    209100 non-null  int64  \n",
      " 28  ALCOHOL_BIN   209100 non-null  int64  \n",
      " 29  VISIT_DATE    209100 non-null  int64  \n",
      " 30  delta_days    209100 non-null  int64  \n",
      " 31  mask          209100 non-null  int64  \n",
      "dtypes: float64(5), int64(26), object(1)\n",
      "memory usage: 51.0+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=pd.read_csv(\"/data/df_mock_timeseries_padded.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19be828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "NACCID          0\n",
      "visit_num       0\n",
      "NACCAGE         0\n",
      "SEX             0\n",
      "EDUC            0\n",
      "HYPERTEN        0\n",
      "DIABETES        0\n",
      "HYPERCHO        0\n",
      "CVHATT          0\n",
      "STROKE          0\n",
      "TOBAC30         0\n",
      "ALCOHOL         0\n",
      "NACCBMI         0\n",
      "NACCFAM         0\n",
      "NACCALZD        0\n",
      "VISITYR         0\n",
      "VISITMO         0\n",
      "VISITDAY        0\n",
      "BPSYS           0\n",
      "COGMODE         0\n",
      "DEPD            0\n",
      "MEMORY          0\n",
      "ORIENT          0\n",
      "BPDIAS          0\n",
      "HYPERTEN_BIN    0\n",
      "DIABETES_BIN    0\n",
      "HYPERCHO_BIN    0\n",
      "CVHATT_BIN      0\n",
      "ALCOHOL_BIN     0\n",
      "VISIT_DATE      0\n",
      "delta_days      0\n",
      "mask            0\n",
      "dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column: NACCID\n",
      "NACCID\n",
      "NACC999872    10\n",
      "NACC000034    10\n",
      "NACC000067    10\n",
      "NACC000162    10\n",
      "NACC000176    10\n",
      "              ..\n",
      "NACC000919    10\n",
      "NACC000903    10\n",
      "NACC000898    10\n",
      "NACC000818    10\n",
      "NACC000792    10\n",
      "Name: count, Length: 20910, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: visit_num\n",
      "visit_num\n",
      "1     20910\n",
      "2     20910\n",
      "3     20910\n",
      "4     20910\n",
      "5     20910\n",
      "6     20910\n",
      "7     20910\n",
      "8     20910\n",
      "9     20910\n",
      "10    20910\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: NACCAGE\n",
      "NACCAGE\n",
      "0      101061\n",
      "76       4402\n",
      "75       4400\n",
      "77       4332\n",
      "74       4329\n",
      "        ...  \n",
      "107         2\n",
      "108         2\n",
      "109         1\n",
      "110         1\n",
      "18          1\n",
      "Name: count, Length: 94, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: SEX\n",
      "SEX\n",
      "0    101061\n",
      "2     61511\n",
      "1     46528\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: EDUC\n",
      "EDUC\n",
      "0     101134\n",
      "16     26230\n",
      "18     23149\n",
      "12     16550\n",
      "14     10946\n",
      "20     10886\n",
      "13      4918\n",
      "15      3489\n",
      "17      2930\n",
      "19      2847\n",
      "10      1009\n",
      "8        877\n",
      "11       873\n",
      "9        538\n",
      "6        494\n",
      "21       416\n",
      "7        306\n",
      "3        305\n",
      "22       298\n",
      "5        177\n",
      "2        153\n",
      "23       136\n",
      "4        129\n",
      "24       100\n",
      "25        84\n",
      "26        43\n",
      "1         42\n",
      "29        13\n",
      "28        10\n",
      "30        10\n",
      "27         8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: HYPERTEN\n",
      "HYPERTEN\n",
      "0    156359\n",
      "1     48595\n",
      "2      4146\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: DIABETES\n",
      "DIABETES\n",
      "0    198278\n",
      "1     10010\n",
      "2       812\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: HYPERCHO\n",
      "HYPERCHO\n",
      "0    160568\n",
      "1     43242\n",
      "2      5290\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: CVHATT\n",
      "CVHATT\n",
      "0    204202\n",
      "2      4348\n",
      "1       550\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: STROKE\n",
      "STROKE\n",
      "0    206556\n",
      "1      2544\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: TOBAC30\n",
      "TOBAC30\n",
      "0    201834\n",
      "1      7266\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: ALCOHOL\n",
      "ALCOHOL\n",
      "0    205037\n",
      "2      3650\n",
      "1       413\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: NACCBMI\n",
      "NACCBMI\n",
      "0.00     101061\n",
      "25.80      1095\n",
      "25.10      1029\n",
      "54.76      1008\n",
      "26.60       969\n",
      "          ...  \n",
      "55.90         1\n",
      "39.34         1\n",
      "14.02         1\n",
      "13.64         1\n",
      "17.04         1\n",
      "Name: count, Length: 1017, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: NACCFAM\n",
      "NACCFAM\n",
      "0    142210\n",
      "1     66890\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: NACCALZD\n",
      "NACCALZD\n",
      "0    168073\n",
      "1     41027\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: VISITYR\n",
      "VISITYR\n",
      "0       101061\n",
      "2010      6838\n",
      "2009      6783\n",
      "2012      6769\n",
      "2013      6645\n",
      "2011      6495\n",
      "2019      6317\n",
      "2014      6312\n",
      "2008      6258\n",
      "2018      5963\n",
      "2016      5665\n",
      "2017      5603\n",
      "2007      5323\n",
      "2022      5263\n",
      "2020      5217\n",
      "2021      5107\n",
      "2015      4811\n",
      "2023      4729\n",
      "2006      3815\n",
      "2024      3327\n",
      "2005       743\n",
      "2025        56\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: VISITMO\n",
      "VISITMO\n",
      "0     101061\n",
      "10     10164\n",
      "3       9926\n",
      "4       9295\n",
      "5       9239\n",
      "8       9172\n",
      "2       9163\n",
      "6       8999\n",
      "11      8917\n",
      "9       8871\n",
      "1       8833\n",
      "7       8358\n",
      "12      7102\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: VISITDAY\n",
      "VISITDAY\n",
      "0     101061\n",
      "12      3864\n",
      "11      3846\n",
      "9       3843\n",
      "8       3833\n",
      "10      3797\n",
      "13      3795\n",
      "7       3782\n",
      "15      3717\n",
      "16      3711\n",
      "6       3703\n",
      "17      3698\n",
      "14      3695\n",
      "18      3693\n",
      "20      3631\n",
      "19      3616\n",
      "21      3600\n",
      "5       3558\n",
      "22      3485\n",
      "3       3465\n",
      "23      3431\n",
      "2       3403\n",
      "1       3395\n",
      "4       3393\n",
      "24      3366\n",
      "28      3283\n",
      "26      3257\n",
      "25      3187\n",
      "27      3173\n",
      "30      3040\n",
      "29      3009\n",
      "31      1770\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: BPSYS\n",
      "BPSYS\n",
      "0.0      101061\n",
      "130.0      4901\n",
      "140.0      4300\n",
      "120.0      3871\n",
      "110.0      2680\n",
      "          ...  \n",
      "185.6         1\n",
      "198.2         1\n",
      "190.8         1\n",
      "105.8         1\n",
      "107.8         1\n",
      "Name: count, Length: 482, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: COGMODE\n",
      "COGMODE\n",
      "0    152280\n",
      "1     55799\n",
      "3       530\n",
      "2       491\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: DEPD\n",
      "DEPD\n",
      "0    183752\n",
      "1     25348\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: MEMORY\n",
      "MEMORY\n",
      "0.0    151093\n",
      "0.5     23623\n",
      "1.0     18709\n",
      "2.0      9989\n",
      "3.0      5686\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: ORIENT\n",
      "ORIENT\n",
      "0.0    169319\n",
      "1.0     13543\n",
      "0.5     12993\n",
      "2.0      7682\n",
      "3.0      5563\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: BPDIAS\n",
      "BPDIAS\n",
      "0.0      101061\n",
      "70.0       8271\n",
      "80.0       7441\n",
      "78.0       4544\n",
      "72.0       4023\n",
      "          ...  \n",
      "351.4         1\n",
      "31.0          1\n",
      "362.6         1\n",
      "353.2         1\n",
      "230.4         1\n",
      "Name: count, Length: 451, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: HYPERTEN_BIN\n",
      "HYPERTEN_BIN\n",
      "0    156359\n",
      "1     52741\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: DIABETES_BIN\n",
      "DIABETES_BIN\n",
      "0    198278\n",
      "1     10822\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: HYPERCHO_BIN\n",
      "HYPERCHO_BIN\n",
      "0    160568\n",
      "1     48532\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: CVHATT_BIN\n",
      "CVHATT_BIN\n",
      "0    204202\n",
      "1      4898\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: ALCOHOL_BIN\n",
      "ALCOHOL_BIN\n",
      "0    205037\n",
      "1      4063\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: VISIT_DATE\n",
      "VISIT_DATE\n",
      "0        101061\n",
      "14677        50\n",
      "16443        50\n",
      "14691        47\n",
      "15657        46\n",
      "          ...  \n",
      "14602         1\n",
      "17292         1\n",
      "20101         1\n",
      "19106         1\n",
      "17838         1\n",
      "Name: count, Length: 5295, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: delta_days\n",
      "delta_days\n",
      "0       121972\n",
      "364       3290\n",
      "371       1931\n",
      "378       1479\n",
      "357       1405\n",
      "         ...  \n",
      "1362         1\n",
      "2536         1\n",
      "1873         1\n",
      "2237         1\n",
      "2055         1\n",
      "Name: count, Length: 1906, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Value counts for column: mask\n",
      "mask\n",
      "1    108039\n",
      "0    101061\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Check missing values for each column\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. Print numerical statistics for each column\n",
    "for col in df.columns:\n",
    "    print(f\"Value counts for column: {col}\")\n",
    "    print(df[col].value_counts(dropna=False))\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145d5cc",
   "metadata": {},
   "source": [
    "## Data Preparation: Long->Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7247cf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tensor shape: torch.Size([20910, 10, 18])\n",
      "mask_tensor shape: torch.Size([20910, 10])\n"
     ]
    }
   ],
   "source": [
    "#Choose features\n",
    "feature_cols = [\"NACCAGE\", \"SEX\", \"EDUC\",  \"STROKE\",\n",
    "    \"TOBAC30\",\"NACCBMI\", \"NACCFAM\", \"BPSYS\", \"BPDIAS\",\"VISITYR\", \"VISITMO\",\n",
    "    \"VISITDAY\",\"HYPERTEN_BIN\", \"DIABETES_BIN\", \"HYPERCHO_BIN\", \"CVHATT_BIN\", \"ALCOHOL_BIN\",\n",
    "    \"delta_days\",]\n",
    "num_features = len(feature_cols)\n",
    "\n",
    "# set default sequence length       (record number of visits per subject)\n",
    "max_seq_len=10          \n",
    "\n",
    "#Sort the data by id and visit number to ensure chronological order and gather one person's data together\n",
    "df=df.sort_values(by=[\"NACCID\",\"visit_num\"])\n",
    "\n",
    "# create a list of unique subjects\n",
    "subjects = df[\"NACCID\"].unique()\n",
    "num_subjects = len(subjects)\n",
    "\n",
    "# Create empty numpy arrays     (Set size in advance to avoid dynamic resizing)     each subject has a 2d array of shape (max_seq_len, num_features)\n",
    "X_array = np.zeros((num_subjects, max_seq_len, num_features), dtype=np.float32)\n",
    "masks_array = np.zeros((num_subjects, max_seq_len), dtype=np.bool_)\n",
    "\n",
    "# Dictionary comprehension to map each NACCID to its index\n",
    "id_to_index = {id: idx for idx, id in enumerate(subjects)}          \n",
    "\n",
    "for id, group in df.groupby('NACCID'):\n",
    "    idx = id_to_index[id]  # Provide the index for the current subject\n",
    "    \n",
    "    # Fill in X_array (max_seq_len, num_features)\n",
    "    X = group[feature_cols].to_numpy()\n",
    "    \n",
    "    # Fill in masks_array (num_subjects, max_seq_len)\n",
    "    m = group['mask'].to_numpy()\n",
    "    \n",
    "    length = len(X)\n",
    "    \n",
    "    # Copy the data into the preallocated arrays\n",
    "    X_array[idx, :length, :] = X[:length]\n",
    "    masks_array[idx, :length] = m[:length]\n",
    "\n",
    "# 10. Convert numpy arrays to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_array)           # shape: (num_subjects, max_seq_len, num_features)\n",
    "mask_tensor = torch.tensor(masks_array)     # shape: (num_subjects, max_seq_len)\n",
    "\n",
    "# Print the shapes of the tensors \n",
    "print(\"X_tensor shape:\", X_tensor.shape)\n",
    "print(\"mask_tensor shape:\", mask_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cee0ac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_tensor shape: torch.Size([20910])\n",
      "y_tensor sample: tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
      "Class count: tensor([11580,  9330])\n"
     ]
    }
   ],
   "source": [
    "subjects = df[\"NACCID\"].unique()\n",
    "\n",
    "grouped = df.groupby('NACCID')\n",
    "\n",
    "last_indices=mask_tensor.sum(axis=1) - 1\n",
    "\n",
    "y_list = []\n",
    "\n",
    "for i, subject_id in enumerate(subjects):\n",
    "    patient_data = grouped.get_group(subject_id)\n",
    "    last_visit_index = last_indices[i].item()  # Get the last index for the current subject\n",
    "\n",
    "    last_alzh=patient_data.iloc[last_visit_index][\"NACCALZD\"]\n",
    "    y_list.append(last_alzh)\n",
    "\n",
    "y_tensor = torch.tensor(y_list, dtype=torch.long)  # shape: (num_subjects,)\n",
    "print(\"y_tensor shape:\", y_tensor.shape)\n",
    "print(\"y_tensor sample:\", y_tensor[:10])  # Print first 10 elements for verification\")    \n",
    "\n",
    "class_count=torch.bincount(y_tensor)\n",
    "print(\"Class count:\", class_count)  # Print the count of each class in y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0252a1d6",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c1a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix,roc_auc_score,precision_score,recall_score,f1_score\n",
    "import numpy as np\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AlzheimerDataset(Dataset):\n",
    "    def __init__(self, X_tensor,mask_tensor,y_tensor):          #initialize dataset\n",
    "        self.X = X_tensor\n",
    "        self.mask = mask_tensor     \n",
    "        self.y=y_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_item = self.X[idx]\n",
    "        mask_item = self.mask[idx]\n",
    "        y_item = self.y[idx]\n",
    "\n",
    "        # If it is numpy array, change innto tensor\n",
    "        if isinstance(X_item, np.ndarray):\n",
    "            X_item = torch.tensor(X_item, dtype=torch.float32)\n",
    "        if isinstance(mask_item, np.ndarray):\n",
    "            mask_item = torch.tensor(mask_item, dtype=torch.float32)\n",
    "        if isinstance(y_item, np.ndarray):\n",
    "            y_item = torch.tensor(y_item, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'X': X_item,\n",
    "            'mask': mask_item,\n",
    "            'y': y_item\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed034a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):   # input_dim = number of features    num_layers = number of layers for LSTM model  \n",
    "        super().__init__()                                               \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers,           # hidden_dim = size of model's hidden state: greater-> more capability, but more chance of overfitting\n",
    "                            batch_first=True, bidirectional=True)        # tensor shape:(seq_len,batch,input_dim) ->(batch,seq_len,input_dim)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)                  # Apply both past to cuerrent and current to past; Thus, hidden_dim*2\n",
    "\n",
    "    def forward(self, X, mask):\n",
    "        out, _ = self.lstm(X)     # (batch, seq_len, hidden_dim*2)  \n",
    "        lengths = mask.sum(dim=1).long() - 1  # last index for real visit  \n",
    "        last_h = out[torch.arange(out.size(0)), lengths]  #  last hidden state    (batchNum,last real visit)\n",
    "        return self.fc(last_h)          #return  group of last sequence for each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0492f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):                                                                  \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():    # Should not change weight or calculate gradients here\n",
    "        for batch in data_loader:\n",
    "            X = batch['X'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            y = batch['y'].to(device)\n",
    "\n",
    "            logits = model(X, mask).squeeze()   # raw output\n",
    "            probs = torch.sigmoid(logits)       # Turn logits into probs\n",
    "            preds = (probs >= 0.5).long()       # Binary prediction\n",
    "\n",
    "            all_preds.append(preds.cpu())       # collect data\n",
    "            all_labels.append(y.cpu())          \n",
    "            all_probs.append(probs.cpu())       \n",
    "\n",
    "    y_true = torch.cat(all_labels).numpy()      # change torch.tensor to numpy arrays\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    y_prob = torch.cat(all_probs).numpy()\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)                         \n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    return acc, auc, precision, recall, f1,y_true, y_pred\n",
    "\n",
    "# Accuracy: % of correct predictions\n",
    "\n",
    "# AUC: How well the model ranks positive samples higher than negative ones\n",
    "\n",
    "# Precision: Among predicted positives, how many were correct?\n",
    "\n",
    "# Recall: Among actual positives, how many did we catch?\n",
    "\n",
    "# F1: Balance between precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e62ee44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_weight: 1.2411575317382812\n"
     ]
    }
   ],
   "source": [
    "# --- Data Preparation (X_tensor, mask_tensor, y_tensor) ---\n",
    "\n",
    "dataset = AlzheimerDataset(X_tensor, mask_tensor, y_tensor)                 # Load the data\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "num_neg = (y_tensor == 0).sum().item()                                # Handle the imbalance\n",
    "num_pos = (y_tensor == 1).sum().item()\n",
    "pos_weight_val = num_neg / num_pos\n",
    "pos_weight = torch.tensor([pos_weight_val], dtype=torch.float32).to(device)\n",
    "print(\"pos_weight:\", pos_weight.item())\n",
    "\n",
    "input_dim = X_tensor.size(2)                                       # num of features\n",
    "hidden_dim = 64\n",
    "num_layers = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LSTMClassifier(input_dim, hidden_dim, num_layers, output_dim).to(device)      # modl initialization\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)    # weight on pos to handle imbalance\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)    # adjust weight during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161d94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 — Loss: 0.7679\n",
      "Train Accuracy: 0.5602, AUC: 0.5738, Precision: 0.5070, Recall: 0.5218, F1: 0.5143\n",
      "Epoch 2/20 — Loss: 0.7612\n",
      "Train Accuracy: 0.5623, AUC: 0.5998, Precision: 0.5073, Recall: 0.6662, F1: 0.5760\n",
      "Epoch 3/20 — Loss: 0.7561\n",
      "Train Accuracy: 0.5738, AUC: 0.5984, Precision: 0.5198, Recall: 0.5871, F1: 0.5514\n",
      "Epoch 4/20 — Loss: 0.7530\n",
      "Train Accuracy: 0.5806, AUC: 0.6167, Precision: 0.5254, Recall: 0.6214, F1: 0.5694\n",
      "Epoch 5/20 — Loss: 0.7477\n",
      "Train Accuracy: 0.5872, AUC: 0.6210, Precision: 0.5347, Recall: 0.5768, F1: 0.5550\n",
      "Epoch 6/20 — Loss: 0.7448\n",
      "Train Accuracy: 0.5946, AUC: 0.6336, Precision: 0.5403, Recall: 0.6133, F1: 0.5745\n",
      "Epoch 7/20 — Loss: 0.7420\n",
      "Train Accuracy: 0.6073, AUC: 0.6404, Precision: 0.5703, Recall: 0.4859, F1: 0.5247\n",
      "Epoch 8/20 — Loss: 0.7400\n",
      "Train Accuracy: 0.6032, AUC: 0.6431, Precision: 0.5499, Recall: 0.6102, F1: 0.5785\n",
      "Epoch 9/20 — Loss: 0.7373\n",
      "Train Accuracy: 0.6095, AUC: 0.6453, Precision: 0.5786, Recall: 0.4594, F1: 0.5121\n",
      "Epoch 10/20 — Loss: 0.7355\n",
      "Train Accuracy: 0.6099, AUC: 0.6508, Precision: 0.5596, Recall: 0.5893, F1: 0.5741\n",
      "Epoch 11/20 — Loss: 0.7338\n",
      "Train Accuracy: 0.6184, AUC: 0.6547, Precision: 0.5842, Recall: 0.5020, F1: 0.5400\n",
      "Epoch 12/20 — Loss: 0.7315\n",
      "Train Accuracy: 0.6207, AUC: 0.6593, Precision: 0.5798, Recall: 0.5445, F1: 0.5616\n",
      "Epoch 13/20 — Loss: 0.7305\n",
      "Train Accuracy: 0.6151, AUC: 0.6548, Precision: 0.6034, Recall: 0.4009, F1: 0.4817\n",
      "Epoch 14/20 — Loss: 0.7286\n",
      "Train Accuracy: 0.6095, AUC: 0.6591, Precision: 0.5503, Recall: 0.6831, F1: 0.6095\n",
      "Epoch 15/20 — Loss: 0.7270\n",
      "Train Accuracy: 0.6193, AUC: 0.6641, Precision: 0.5684, Recall: 0.6098, F1: 0.5883\n",
      "Epoch 16/20 — Loss: 0.7262\n",
      "Train Accuracy: 0.6132, AUC: 0.6631, Precision: 0.5556, Recall: 0.6653, F1: 0.6055\n",
      "Epoch 17/20 — Loss: 0.7243\n",
      "Train Accuracy: 0.6069, AUC: 0.6622, Precision: 0.5466, Recall: 0.6989, F1: 0.6134\n",
      "Epoch 18/20 — Loss: 0.7233\n",
      "Train Accuracy: 0.6253, AUC: 0.6684, Precision: 0.5791, Recall: 0.5870, F1: 0.5830\n",
      "Epoch 19/20 — Loss: 0.7223\n",
      "Train Accuracy: 0.6265, AUC: 0.6693, Precision: 0.5836, Recall: 0.5692, F1: 0.5763\n",
      "Epoch 20/20 — Loss: 0.7216\n",
      "Train Accuracy: 0.6264, AUC: 0.6719, Precision: 0.5771, Recall: 0.6096, F1: 0.5929\n",
      "\n",
      "Confusion Matrix (Best Model):\n",
      "[[6170 5410]\n",
      " [2809 6521]]\n",
      "\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6872    0.5328    0.6002     11580\n",
      "           1     0.5466    0.6989    0.6134      9330\n",
      "\n",
      "    accuracy                         0.6069     20910\n",
      "   macro avg     0.6169    0.6159    0.6068     20910\n",
      "weighted avg     0.6244    0.6069    0.6061     20910\n",
      "\n",
      "\n",
      "Best Train Performance (by Recall):\n",
      "Accuracy: 0.6069\n",
      "AUC: 0.6622\n",
      "Precision: 0.5466\n",
      "Recall: 0.6989\n",
      "F1 Score: 0.6134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (lstm): LSTM(18, 64, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "best_recall = 0\n",
    "best_metrics = {}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        x_batch = batch['X'].to(device)             # (batch, seq_len, features)\n",
    "        m_batch = batch['mask'].to(device)          # (batch, seq_len)\n",
    "        y_batch = batch['y'].float().to(device).view(-1,1)  # (batch, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x_batch, m_batch)             # (batch, output_dim)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} — Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    acc, auc, prec, rec, f1, y_true, y_pred = evaluate(model, train_loader)\n",
    "    print(f\"Train Accuracy: {acc:.4f}, AUC: {auc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    if rec > best_recall and prec > 0.5:\n",
    "        best_recall = rec\n",
    "        best_metrics = {\n",
    "            'acc': acc,\n",
    "            'auc': auc,\n",
    "            'precision': prec,\n",
    "            'recall': rec,\n",
    "            'f1': f1,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred\n",
    "        }\n",
    "        torch.save(model.state_dict(), 'best_model_by_recall2.pt')\n",
    "\n",
    "print(\"\\nConfusion Matrix (Best Model):\")\n",
    "print(confusion_matrix(best_metrics['y_true'], best_metrics['y_pred']))\n",
    "\n",
    "print(\"\\nClassification Report (Best Model):\")\n",
    "print(classification_report(best_metrics['y_true'], best_metrics['y_pred'], digits=4))\n",
    "\n",
    "print(\"\\nBest Train Performance (by Recall):\")\n",
    "print(f\"Accuracy: {best_metrics['acc']:.4f}\")\n",
    "print(f\"AUC: {best_metrics['auc']:.4f}\")\n",
    "print(f\"Precision: {best_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {best_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {best_metrics['f1']:.4f}\")\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_by_recall2.pt'))\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
